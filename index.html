<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>MYENDLESS</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta property="og:type" content="website">
<meta property="og:title" content="MYENDLESS">
<meta property="og:url" content="https://myendless1.github.io/index.html">
<meta property="og:site_name" content="MYENDLESS">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Li Ying">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="MYENDLESS" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">MYENDLESS</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS Feed"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="Search"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://myendless1.github.io"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main">
  
    <article id="post-拉格朗日乘子法与对偶问题/拉格朗日乘子法与对偶问题" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/07/02/%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95%E4%B8%8E%E5%AF%B9%E5%81%B6%E9%97%AE%E9%A2%98/%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95%E4%B8%8E%E5%AF%B9%E5%81%B6%E9%97%AE%E9%A2%98/" class="article-date">
  <time class="dt-published" datetime="2023-07-02T01:04:46.000Z" itemprop="datePublished">2023-07-02</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2023/07/02/%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95%E4%B8%8E%E5%AF%B9%E5%81%B6%E9%97%AE%E9%A2%98/%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95%E4%B8%8E%E5%AF%B9%E5%81%B6%E9%97%AE%E9%A2%98/">拉格朗日乘子法与对偶问题</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>之前上科研课堂《复杂网络》时计算机学院的潘老师给我们讲过线性规划的对偶问题，但已经忘了如何从原问题转化到到对偶问题了。今天在周志华的《机器学习》一书中见到了使用拉格朗日乘子法来求对偶问题的方法，觉得有必要学习，同时记此笔记。</p>
<p>本文引用内容主要来源于知乎，原链接：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/114574438">拉格朗日乘子法与对偶问题 - 知乎 (zhihu.com)</a>、<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/111723231">梯度、方向导数与等值面 - 知乎 (zhihu.com)</a>。仅作为学习使用。</p>
<h2 id="梯度与等值面"><a href="#梯度与等值面" class="headerlink" title="梯度与等值面"></a>梯度与等值面</h2><ul>
<li>函数值最快下降的方向是梯度。函数$f$的梯度记为$\bigtriangledown f$。</li>
<li>空间中函数值相等的面叫等值面，函数值相等的线叫等值线。</li>
<li>沿梯度方向移动到下一个等值面（或等值线）的速度最快，梯度垂直于函数的等值面。</li>
</ul>
<h2 id="等式约束"><a href="#等式约束" class="headerlink" title="等式约束"></a>等式约束</h2><p><img src="/.io//Users\34707\blog\source_posts\等值面和约束曲面.webp" alt="等值面和约束曲面"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://myendless1.github.io/2023/07/02/%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95%E4%B8%8E%E5%AF%B9%E5%81%B6%E9%97%AE%E9%A2%98/%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95%E4%B8%8E%E5%AF%B9%E5%81%B6%E9%97%AE%E9%A2%98/" data-id="cljkrlhlj00003gsh0mc26hql" data-title="拉格朗日乘子法与对偶问题" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%91%A8%E5%BF%97%E5%8D%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag">周志华机器学习</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-先验概率-后验概率" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/06/23/%E5%85%88%E9%AA%8C%E6%A6%82%E7%8E%87-%E5%90%8E%E9%AA%8C%E6%A6%82%E7%8E%87/" class="article-date">
  <time class="dt-published" datetime="2023-06-23T07:54:41.000Z" itemprop="datePublished">2023-06-23</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2023/06/23/%E5%85%88%E9%AA%8C%E6%A6%82%E7%8E%87-%E5%90%8E%E9%AA%8C%E6%A6%82%E7%8E%87/">先验概率&amp;后验概率</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="一、全概率公式"><a href="#一、全概率公式" class="headerlink" title="一、全概率公式"></a>一、全概率公式</h2><p>设事件$B_1$,$B_2$,$B_3$,…,$B_n$构成一个完备事件组，即两两互斥且并集为全集$S$。则对于任一事件 $A$有<br>$$<br>P(A)&#x3D;\sum_{i&#x3D;1}^{n}P(B_i)P(A|B_i)\tag1<br>$$<br>全概率公式是“由因推果”的思想。</p>
<h2 id="二、贝叶斯公式"><a href="#二、贝叶斯公式" class="headerlink" title="二、贝叶斯公式"></a>二、贝叶斯公式</h2><p>符号定义同上，有：<br>$$<br>P(B_i|A)&#x3D;\frac{P(B_i)P(A|B_i)}{P(A)}&#x3D;\frac{P(B_i)P(A|B_i)}{\sum_{i&#x3D;1}^{n}P(B_i)P(A|B_i)}\tag2<br>$$<br>贝叶斯公式是“由果溯因”的思想。</p>
<h2 id="三、先验概率和后验概率"><a href="#三、先验概率和后验概率" class="headerlink" title="三、先验概率和后验概率"></a>三、先验概率和后验概率</h2><p><strong>先验概率（prior probability）：</strong>指根据以往经验和分析。在实验或采样前就可以得到的概率。</p>
<p><strong>后验概率（posterior probability）：</strong>指某件事已经发生，想要计算这件事发生的原因是由某个因素引起的概率。</p>
<p>引自@<strong>笨笨</strong>（<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/38567891">&lt;基础系列&gt;1：先验概率 &amp; 后验概率 - 知乎 (zhihu.com)</a>）</p>
<h3 id="观测值角度"><a href="#观测值角度" class="headerlink" title="观测值角度"></a>观测值角度</h3><p><strong>先验概率</strong>：没有观测值时使用经验来得出的概率。</p>
<p><strong>后验概率</strong>：通过观测值反推未观测事件（无法观测事件）发生的概率，推测过程常需要使用先验概率。</p>
<p>总结自@<strong>鸡蛋口语</strong>（ <a target="_blank" rel="noopener" href="https://www.zhihu.com/question/315348473/answer/618943610%EF%BC%89">https://www.zhihu.com/question/315348473/answer/618943610）</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://myendless1.github.io/2023/06/23/%E5%85%88%E9%AA%8C%E6%A6%82%E7%8E%87-%E5%90%8E%E9%AA%8C%E6%A6%82%E7%8E%87/" data-id="clj8b63kx0000k8sheptz3oga" data-title="先验概率&amp;后验概率" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%91%A8%E5%BF%97%E5%8D%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag">周志华机器学习</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-logistic_regression" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/06/19/logistic_regression/" class="article-date">
  <time class="dt-published" datetime="2023-06-19T12:43:07.000Z" itemprop="datePublished">2023-06-19</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2023/06/19/logistic_regression/">逻辑回归代价函数求导过程</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>逻辑回归代价函数如下：<br>$$<br>J(\vec{w},b)&#x3D;-\frac{1}{m}\sum_{i&#x3D;1}^{m}{[y^{(i)}log(f_{\vec{w},b}(\vec{x}^{(i)})+(1-y^{(i)})log(1-f_{\vec{w},b}(\vec{x}^{(i)}))]}\tag{1}<br>$$<br>其求导结果如下：<br>$$<br>\frac{\partial }{\partial w_j}J(\vec{w},b)&#x3D;\frac{1}{m}\sum_{i&#x3D;1}^{m}(f_{\vec{w},b}(\vec{x}^{(i)})-y^{(i)})x_j^{(i)}\tag{2}<br>$$</p>
<p>$$<br>\frac{\partial }{\partial b}J(\vec{w},b)&#x3D;\frac{1}{m}\sum_{i&#x3D;1}^{m}(f_{\vec{w},b}(\vec{x}^{(i)})-y^{(i)})\tag{3}<br>$$</p>
<p>以对$$w_j$$的偏导数为例，其计算过程如下：</p>
<p>已知：<br>$$<br>f_{\vec{w},b}(\vec{x}^{(i)})&#x3D;\frac{1}{1+e^{-(\vec{w}^T\vec{x}+b)}}	\tag{4}<br>$$<br>将sigmoid函数$$f$$对$$w_j$$求偏导数得：</p>
<p>$$<br>f_{\vec{w},b}^{‘}(\vec{x}^{(i)})&#x3D;\frac{\vec{x}^{(i)}<em>je^{\vec{w}^T\vec{x}+b}}{(1+e^{-(\vec{w}^T\vec{x}+b)})^{2}}&#x3D;\vec{x}^{(i)}<em>jf</em>{\vec{w},b}(\vec{x}^{(i)})(1-f</em>{\vec{w},b}(\vec{x}^{(i)}))\tag{5}<br>$$<br>将总损失函数$$J(\vec{w},b)$$对$$w_j$$求偏导数得：</p>
<p>$$<br>\frac{\partial }{\partial w_j}J(\vec{w},b)&#x3D;-\frac{1}{m}\sum_{i&#x3D;1}^{m}[y^{(i)}f_{\vec{w},b}^{‘}(\vec{x}^{(i)})\frac{1}{f_{\vec{w},b}(\vec{x}^{(i)})}-f_{\vec{w},b}^{‘}(\vec{x}^{(i)})(1-y^{(i)})\frac{1}{1-f_{\vec{w},b}(\vec{x}^{(i)})}]\tag{6}<br>$$<br>将（5）式代入（6）式得</p>
<p>$$<br>\frac{\partial }{\partial w_j}J(\vec{w},b)<br>$$</p>
<p>$$<br>&#x3D;-\frac{1}{m}\sum_{i&#x3D;1}^{m}x_j^{(i)}f_{\vec{w},b}(\vec{x}^{(i)})(1-f_{\vec{w},b}(\vec{x}^{(i)}))[y^{(i)}\frac{1}{f_{\vec{w},b}(\vec{x}^{(i)})}-(1-y^{(i)})\frac{1}{1-f_{\vec{w},b}(\vec{x}^{(i)})}]<br>$$</p>
<p>$$<br>&#x3D;-\frac{1}{m}\sum_{i&#x3D;1}^{m}[y^{(i)}(1-f_{\vec{w},b}(\vec{x}^{(i)}))-(1-y^{(i)})f_{\vec{w},b}(\vec{x}^{(i)})]x_j^{(i)}<br>$$</p>
<p>$$<br>&#x3D;-\frac{1}{m}\sum_{i&#x3D;1}^{m}[y^{(i)}-f_{\vec{w},b}(\vec{x}^{(i)})]x_j^{(i)}<br>$$</p>
<p>$$<br>&#x3D;\frac{1}{m}\sum_{i&#x3D;1}^{m}[f_{\vec{w},b}(\vec{x}^{(i)})-y^{(i)}]x_j^{(i)}<br>\tag{7}<br>$$</p>
<p>对b求导结果类似。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://myendless1.github.io/2023/06/19/logistic_regression/" data-id="clj36y9x90000zcsh1cxkhfql" data-title="逻辑回归代价函数求导过程" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/deeplearning-ai/" rel="tag">deeplearning.ai</a></li></ul>

    </footer>
  </div>
  
</article>



  


</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/deeplearning-ai/" rel="tag">deeplearning.ai</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%91%A8%E5%BF%97%E5%8D%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag">周志华机器学习</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/deeplearning-ai/" style="font-size: 10px;">deeplearning.ai</a> <a href="/tags/%E5%91%A8%E5%BF%97%E5%8D%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" style="font-size: 20px;">周志华机器学习</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/06/">June 2023</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2023/07/02/%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95%E4%B8%8E%E5%AF%B9%E5%81%B6%E9%97%AE%E9%A2%98/%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95%E4%B8%8E%E5%AF%B9%E5%81%B6%E9%97%AE%E9%A2%98/">拉格朗日乘子法与对偶问题</a>
          </li>
        
          <li>
            <a href="/2023/06/23/%E5%85%88%E9%AA%8C%E6%A6%82%E7%8E%87-%E5%90%8E%E9%AA%8C%E6%A6%82%E7%8E%87/">先验概率&amp;后验概率</a>
          </li>
        
          <li>
            <a href="/2023/06/19/logistic_regression/">逻辑回归代价函数求导过程</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2023 Li Ying<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>